text-to-SQL Bot (Graph-Driven, Safe by Design)

A production-grade Text-to-SQL system that converts natural-language questions into safe, validated SQL over uploaded CSV files.

The system is built using LangGraph, DuckDB, and Gemini (via LangChain), and follows a compiler-style pipeline where each step is isolated, testable, and safe by construction.

âœ¨ Key Highlights

ğŸ”’ SQL Safety First (SELECT-only, validation gates)

ğŸ§© Graph-driven architecture (LangGraph)

ğŸ§  LLM used only for SQL generation (never execution)

ğŸ§± Schema hallucination prevention

ğŸ§ª Fully testable node-based design

ğŸ“œ Conversation-aware (SQL history & context)

âš¡ Deterministic fallbacks (no hard dependency on embeddings)

ğŸ³ Dockerized deployment (Python 3.11, Docker Compose)

ğŸ“‚ Full Project Structure
text-to-sql/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ exception.py
â”‚   â”œâ”€â”€ gemini_client.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ csv_loader.py
â”‚   â”œâ”€â”€ schema_store.py
â”‚   â”œâ”€â”€ vector_search.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ sql_executor.py
â”‚   â”œâ”€â”€ llm_flow.py
â”‚   â”œâ”€â”€ langsmith_client.py
â”‚   â”œâ”€â”€ tools.py
â”‚   â”œâ”€â”€ history_sql.py
â”‚   â””â”€â”€ graph/
â”‚       â”œâ”€â”€ builder.py
â”‚       â”œâ”€â”€ agent.py
â”‚       â””â”€â”€ nodes/
â”‚           â”œâ”€â”€ generate_node.py
â”‚           â”œâ”€â”€ prompt_node.py
â”‚           â”œâ”€â”€ retrieve_node.py
â”‚           â”œâ”€â”€ validate_node.py
â”‚           â”œâ”€â”€ execute_node.py
â”‚           â”œâ”€â”€ summary_node.py
â”‚           â”œâ”€â”€ format_node.py
â”‚           â”œâ”€â”€ context_node.py
â”‚           â””â”€â”€ error_node.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_generate_node.py
â”‚   â”œâ”€â”€ test_execute_node.py
â”‚   â”œâ”€â”€ test_csv_loader.py
â”‚   â”œâ”€â”€ test_history_sql.py
â”‚   â””â”€â”€ test_summary_node.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .github/workflows/ci.yml
â””â”€â”€ PROJECT_REPORT.md

ğŸ§­ Overall Application Flow (Birdâ€™s-Eye View)
User (Streamlit UI)
        â†“
app.py
        â†“
GraphBuilder (LangGraph)
        â†“
[ Context â†’ Retrieve â†’ Generate â†’ Validate â†’ Execute â†’ Format ]
        â†“
Results shown in UI + SQL History stored


The application is stateless per request, deterministic where possible, and safe by design.

ğŸš€ 1ï¸âƒ£ App Startup Flow (Cold Start)
When you run:
streamlit run app.py

1.1 Configuration & Environment

Files

config.py

.env

Purpose

Loads API keys

Model names

Paths (DuckDB, FAISS, schema store)

1.2 CSV & Schema Infrastructure

Files

csv_loader.py

schema_store.py

database.py

Purpose

CSVs â†’ DuckDB tables

Schema metadata persisted in schema_store.json

Prevents LLM schema hallucination

1.3 Vector Search (Optional RAG)

File

vector_search.py

Purpose

Semantic retrieval for hints (columns, docs)

Gracefully degrades to deterministic behavior

1.4 LLM & Tools Initialization

Files

gemini_client.py

tools.py

Purpose

Wraps Gemini via LangChain

Single Tools object injected into all nodes

1.5 Graph Construction

Files

graph/builder.py

graph/agent.py

Purpose

Wires nodes into a deterministic pipeline

Stateless, reusable per request

âš™ï¸ 2ï¸âƒ£ Runtime Flow (User Query)
Example user input:

â€œWhich app has the highest installs?â€

2.1 UI Layer

File

app.py

Responsibilities

Read user input

Select active schemas

Call graph.run(...)

Render results or warnings

2.2 Context Node

File

graph/nodes/context_node.py

Purpose

Fetch recent SQL history

Enables follow-up questions

Never affects correctness

Output

{
  "conversation_history": [...],
  "last_successful_sql": "SELECT ..."
}

2.3 Retrieve Node (Optional RAG)

File

graph/nodes/retrieve_node.py

Purpose

Semantic lookup (docs, hints)

Safe to skip

Never blocks the pipeline

2.4 Generate Node (Core Intelligence)

File

graph/nodes/generate_node.py

Purpose

Converts natural language â†’ SQL

Enforces:

SELECT-only

Safe casting

Dirty-data handling

ğŸš¨ This node NEVER executes SQL

2.5 Validate Node (Safety Gate)

File

graph/nodes/validate_node.py

Purpose

SQL validation via sqlglot

Rejects:

Non-SELECT queries

Forbidden tables

Invalid SQL

Invalid SQL â†’ ErrorNode

2.6 Execute Node

Files

graph/nodes/execute_node.py

database.py

sql_executor.py

Purpose

Executes validated SQL

Read-only enforcement

Measures execution time

2.7 Format Node

File

graph/nodes/format_node.py

Purpose

Pretty SQL formatting

UI-friendly tables

2.8 History Store

File

history_sql.py

Purpose

Persist:

User query

Generated SQL

Success / failure

Enables conversational memory

2.9 Graph Completion

File

graph/builder.py

Returns final structured output to app.py.

âŒ 3ï¸âƒ£ Error Flow
Generate â†’ Validate âŒ
        â†“
ErrorNode
        â†“
Structured error â†’ UI warning


File

graph/nodes/error_node.py

The graph never crashes â€” all failures are captured and reported safely.

ğŸ§  4ï¸âƒ£ Mental Model for Contributors

Think of this system as:

â€œA compiler pipeline for SQL, driven by a graph, with LLMs acting only as a controlled code generator.â€

ğŸ§© 5ï¸âƒ£ How to Add a New Node (Walkthrough)
Step 1: Create the Node File
# graph/nodes/audit_node.py
from typing import Dict, Any
from app.logger import get_logger

logger = get_logger("audit_node")

class AuditNode:
    def __init__(self):
        logger.info("AuditNode initialized")

    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        sql = state.get("sql")
        logger.info("Auditing SQL length=%s", len(sql or ""))
        return {"audit_passed": True}

Step 2: Register the Node in GraphBuilder
from app.graph.nodes.audit_node import AuditNode

audit_node = AuditNode()

graph.add_node("audit", audit_node.run)
graph.add_edge("validate", "audit")
graph.add_edge("audit", "execute")

Step 3: Define Input / Output Contract

Takes state: Dict[str, Any]

Returns a partial update

Must not mutate unrelated keys

Step 4: Add Tests
def test_audit_node():
    node = AuditNode()
    out = node.run({"sql": "SELECT 1"})
    assert out["audit_passed"] is True

Step 5: Log Everything

Every node must log:

Initialization

Run start

Key decisions

ğŸ§ª Testing Philosophy

One test file per node

No LLM calls in unit tests

Deterministic inputs & outputs

ğŸ›¡ï¸ Why This Architecture Works

âœ… Stateless execution

âœ… Multiple safety layers

âœ… Deterministic fallbacks

âœ… Easy extensibility

âœ… Production-grade logging

ğŸ³ Docker & Deployment
Prerequisites

Docker

Docker Compose

Environment Setup

Create .env:

GOOGLE_API_KEY=your_api_key_here

Build & Run (Recommended)
docker-compose up --build


Open:

http://localhost:8501

Stop Cleanly
Ctrl + C
docker-compose down

Why Docker?

Reproducible environment

Python version pinned (3.11)

One-command startup

Safe isolation of dependencies

Resume-grade deployment practice

ğŸ§ª CI & Quality Gates

GitHub Actions (.github/workflows/ci.yml)

Runs:

Unit tests

Lint checks

Prevents unsafe changes to core pipeline

ğŸ“Œ Final Notes

This project demonstrates:

LLM safety engineering

Graph-driven system design

Production-ready deployment

Testable, deterministic AI pipelines

It is intentionally designed to be:

Safe by default, debuggable by design, and extensible without fear.